{
  "Mlr": 1e-05,
  "auxi_lambda": 0.1,
  "batch_size": 64,
  "cf_dim": 32,
  "d_ff": 64,
  "d_model": 16,
  "dc_lambda": 0.1,
  "e_layers": 3,
  "head_dim": 32,
  "lr": 0.0001,
  "n_heads": 16,
  "num_epochs": 3,
  "patch_size": 16,
  "patch_stride": 8,
  "seq_len": 96
}
